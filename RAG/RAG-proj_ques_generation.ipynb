{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12e5168-de0c-4e2c-8846-9a4253a8409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4351d4ad-9a77-4c02-811c-ff762b3a86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e80a8b6f-cc71-4b09-9b46-04008cb4d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the projects dataset\n",
    "def load_projects_dataset(file_path: str) -> list:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Create a vector store from the projects dataset\n",
    "def create_vector_store(projects_data: list):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for project in projects_data:\n",
    "        content = project[\"content\"]\n",
    "        questions = project[\"questions\"]\n",
    "        for question in questions:\n",
    "            texts.append(question)\n",
    "            metadatas.append({\"content\": content})\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.create_documents(texts, metadatas=metadatas)\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "# Retrieve relevant questions from the vector store\n",
    "def retrieve_relevant_questions(vector_store, query: str, k: int = 5):\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "# Generate additional questions using Groq Llama model\n",
    "def generate_additional_questions(project_description: str, retrieved_questions: list = None) -> list:\n",
    "    if retrieved_questions:\n",
    "        prompt = f\"\"\"\n",
    "        Given the following project description and a set of relevant questions, generate 5 insightful and relevant questions by taking ralvant questions into consideration that could be asked in an interview about the project:\n",
    "\n",
    "        Project Description:\n",
    "        {project_description}\n",
    "\n",
    "        Relevant Questions:\n",
    "        {retrieved_questions}\n",
    "\n",
    "        Return the questions in a JSON array format:\n",
    "        [\n",
    "            \"<Question 1>\",\n",
    "            \"<Question 2>\",\n",
    "            \"<Question 3>\",\n",
    "            ...\n",
    "        ]\n",
    "\n",
    "        Important:\n",
    "        1. Focus on the details in the project description, such as technologies, methods, and challenges faced.\n",
    "        2. Ensure the questions are tailored to the project.\n",
    "        3. Return ONLY the JSON array, no additional text.\n",
    "        4. i need only 5 questions to be returned finally, which should not be from ' Relevant Questions', just take them as reference\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "        Given the following project description, generate 10 insightful and relevant questions that could be asked in an interview about the project:\n",
    "\n",
    "        Project Description:\n",
    "        {project_description}\n",
    "\n",
    "        Return the questions in a JSON array format:\n",
    "        [\n",
    "            \"<Question 1>\",\n",
    "            \"<Question 2>\",\n",
    "            \"<Question 3>\",\n",
    "            ...\n",
    "        ]\n",
    "\n",
    "        Important:\n",
    "        1. Focus on the details in the project description, such as technologies, methods, and challenges faced.\n",
    "        2. Ensure the questions are tailored to the project.\n",
    "        3. Return ONLY the JSON array, no additional text.\n",
    "        \"\"\"\n",
    "\n",
    "    chat = ChatGroq(\n",
    "        api_key=\"",\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        messages = [\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        response = chat.invoke(messages)\n",
    "        content = response.content\n",
    "\n",
    "        # Parse and validate the JSON response\n",
    "        parsed_content = json.loads(content)\n",
    "\n",
    "        return parsed_content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6407783-4b55-4e04-a196-73e2529e2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without RAG: Directly generate questions using the Groq Llama model\n",
    "\n",
    "\n",
    "def generate_questions_without_rag(project_description: str) -> list:\n",
    "    return generate_additional_questions(project_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710def0d-b506-4058-b92c-be4d301e8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With RAG: Retrieve relevant questions and generate additional questions\n",
    "\n",
    "\n",
    "def generate_questions_with_rag(project_description: str, projects_dataset_path: str) -> list:\n",
    "    # Load the projects dataset\n",
    "    projects_data = load_projects_dataset(projects_dataset_path)\n",
    "\n",
    "    # Create a vector store\n",
    "    vector_store = create_vector_store(projects_data)\n",
    "\n",
    "    # Retrieve relevant questions\n",
    "    retrieved_questions = retrieve_relevant_questions(vector_store, project_description)\n",
    "    print(\"\\n relavant projects from our db: \\n\")\n",
    "    print(retrieved_questions)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Generate additional questions\n",
    "    additional_questions = generate_additional_questions(project_description, retrieved_questions)\n",
    "\n",
    "    # Combine retrieved and generated questions\n",
    "    all_questions = retrieved_questions + additional_questions\n",
    "\n",
    "    return all_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf14160f-449a-4ef3-b466-d2af02f5571b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Calculator App: A fully functional calculator that performs basic arithmetic operations with a clean, modern interface. Features include number input, operations (+, -, *, /), decimal points, and clear functionality.',\n",
       "  'questions': ['How did you handle the decimal point logic?',\n",
       "   'How did you implement operator precedence?',\n",
       "   'What approach did you use for error handling?',\n",
       "   'How did you manage state for the calculations?',\n",
       "   'How did you handle keyboard input support?'],\n",
       "  'answers': ['Used a flag variable to track decimal point state and prevent multiple decimals in one number',\n",
       "   'Implemented using an array of operations and processing them in BODMAS order',\n",
       "   'Added try-catch blocks for division by zero and invalid operations, showing user-friendly error messages',\n",
       "   'Used separate variables for currentNumber, previousNumber, and operator, updating display accordingly',\n",
       "   'Added event listeners for keydown events, mapping keyboard keys to calculator functions']},\n",
       " {'content': 'Todo List: A feature-rich task management application with the ability to add, edit, delete, and mark tasks as complete. Includes filtering and local storage persistence.',\n",
       "  'questions': ['How did you implement task persistence?',\n",
       "   'What was your approach to task filtering?',\n",
       "   'How did you handle task editing?',\n",
       "   'How did you implement drag-and-drop?',\n",
       "   'What was your state management approach?'],\n",
       "  'answers': ['Used localStorage to save tasks as JSON strings, parsing them on page load',\n",
       "   'Created filter functions for all/active/completed tasks, updating DOM based on current filter',\n",
       "   'Implemented inline editing with contentEditable and blur event handlers',\n",
       "   'Used HTML5 Drag and Drop API with dragstart and drop events',\n",
       "   'Maintained a tasks array as single source of truth, updating UI on state changes']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_dataset_path = \"merged_projects.json\" \n",
    "\n",
    "with open(projects_dataset_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d410a810-ddd9-4c00-8467-2a227bc585b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without RAG:\n",
      "[\n",
      "  \"What inspired you to choose the MERN stack for the AI-powered image generation web application, and how did you handle potential limitations?\",\n",
      "  \"Can you walk me through the process of integrating AI-powered image generation capabilities into the web application, and what libraries or frameworks did you use?\",\n",
      "  \"How did you design the database schema for the application using MongoDB, and what considerations did you take into account for data storage and retrieval?\",\n",
      "  \"What were some of the most significant challenges you faced while developing the application, and how did you overcome them?\",\n",
      "  \"How did you ensure the scalability and performance of the application, particularly when handling a large volume of image generation requests?\",\n",
      "  \"What measures did you take to secure the application and protect user data, especially considering the use of AI-powered image generation?\",\n",
      "  \"Can you describe the React components and architecture you used to build the frontend of the application, and how you handled state management?\",\n",
      "  \"How did you handle errors and exceptions in the application, particularly when dealing with AI-powered image generation failures or timeouts?\",\n",
      "  \"What testing strategies and tools did you employ to ensure the application was thoroughly tested, including unit tests, integration tests, and end-to-end tests?\",\n",
      "  \"How do you envision the application evolving in the future, and what potential features or enhancements would you like to add to further improve the user experience?\"\n",
      "]\n",
      "With RAG:\n",
      "\n",
      " relavant projects from our db: \n",
      "\n",
      "['How did you implement image export?', 'What image processing libraries did you use?', 'How did you implement thumbnails?', 'How did you implement the photo editing features?', 'How did you implement image zoom?']\n",
      "\n",
      "\n",
      "[\n",
      "  \"How did you implement image export?\",\n",
      "  \"What image processing libraries did you use?\",\n",
      "  \"How did you implement thumbnails?\",\n",
      "  \"How did you implement the photo editing features?\",\n",
      "  \"How did you implement image zoom?\",\n",
      "  \"What were some of the key challenges you faced while integrating the AI-powered image generation functionality with the MERN stack, and how did you overcome them?\",\n",
      "  \"Can you walk me through your decision-making process behind choosing the MERN stack for this project, and how it contributed to the overall success of the application?\",\n",
      "  \"How did you handle image storage and retrieval in the application, and what measures did you take to optimize storage and reduce latency?\",\n",
      "  \"What AI algorithms or models did you use for image generation, and how did you fine-tune them to produce high-quality images?\",\n",
      "  \"How did you ensure the scalability and performance of the application, particularly when handling a large volume of image generation requests?\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "project_description = \"\"\"\n",
    " Developed an AI-powered image generation web application using the MERN stack\n",
    "\"\"\"\n",
    "\n",
    "# Without RAG\n",
    "print(\"Without RAG:\")\n",
    "questions_without_rag = generate_questions_without_rag(project_description)\n",
    "print(json.dumps(questions_without_rag, indent=2))\n",
    "\n",
    "# With RAG\n",
    "print(\"With RAG:\")\n",
    "questions_with_rag = generate_questions_with_rag(project_description, projects_dataset_path)\n",
    "print(json.dumps(questions_with_rag, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bde4b78-f5d2-445c-a346-28735e9b17fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without RAG:\n",
      "[\n",
      "  \"What was the reasoning behind choosing the MERN stack for this project, and how did it influence the development process?\",\n",
      "  \"Can you walk me through the authentication flow for user account creation and login, and how you handled security concerns?\",\n",
      "  \"How did you design the database schema to support blog post storage and retrieval, and what considerations did you take for scalability?\",\n",
      "  \"What measures did you take to ensure seamless user experience when posting blogs, and how did you handle potential errors or exceptions?\",\n",
      "  \"How did you implement user authorization and access control to restrict certain features or actions, such as editing or deleting blog posts?\",\n",
      "  \"What were some of the challenges you faced while building the project, and how did you overcome them?\",\n",
      "  \"Can you describe your approach to handling user input validation and sanitization to prevent common web vulnerabilities like XSS or SQL injection?\",\n",
      "  \"How did you optimize the performance of the application, particularly when dealing with a large number of blog posts or concurrent user activity?\",\n",
      "  \"What testing strategies did you employ to ensure the reliability and stability of the application, and what tools or frameworks did you use?\",\n",
      "  \"Are there any plans for future development or expansion of the project, such as adding new features or integrating with other services?\"\n",
      "]\n",
      "With RAG:\n",
      "\n",
      " relavant projects from our db: \n",
      "\n",
      "['How did you manage user presence?', 'What features did you implement for user convenience?', 'How did you manage user authentication?', 'How did you manage user authentication?', 'How did you manage webhooks?']\n",
      "\n",
      "\n",
      "[\n",
      "  \"How did you manage user presence?\",\n",
      "  \"What features did you implement for user convenience?\",\n",
      "  \"How did you manage user authentication?\",\n",
      "  \"How did you manage user authentication?\",\n",
      "  \"How did you manage webhooks?\",\n",
      "  \"What were some of the challenges you faced while implementing the MERN stack for this project, and how did you overcome them?\",\n",
      "  \"Can you walk me through your approach to handling blog post data, including storage and retrieval using MongoDB?\",\n",
      "  \"How did you ensure seamless user experience during the account creation and login process, and what measures did you take to handle potential errors?\",\n",
      "  \"What considerations did you take into account when designing the frontend of the application using React, and how did you optimize it for performance?\",\n",
      "  \"How do you plan to scale the application to handle a large number of users and blog posts, and what strategies would you use to maintain its performance?\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "project_description = \"\"\"\n",
    " Built on the MERN stack, allows users to create accounts, log in, and post blogs seamlessly\n",
    "\"\"\"\n",
    "\n",
    "# Without RAG\n",
    "print(\"Without RAG:\")\n",
    "questions_without_rag = generate_questions_without_rag(project_description)\n",
    "print(json.dumps(questions_without_rag, indent=2))\n",
    "\n",
    "# With RAG\n",
    "print(\"With RAG:\")\n",
    "questions_with_rag = generate_questions_with_rag(project_description, projects_dataset_path)\n",
    "print(json.dumps(questions_with_rag, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ce8d1-c03b-47cd-9d0b-62960fef8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Observations:\n",
    "\n",
    "# Without RAG: Questions are generic and based solely on the model's understanding.\n",
    "\n",
    "# With RAG: Questions are more detailed and context-aware, leveraging both the dataset and the model's generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade3af0-7413-4185-a89f-37ed57aab1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
